# HMT-ECGNet  
**Lightweight Hierarchical Multi-Lead ECG Classification on PTB-XL**

---

## Overview

**HMT-ECGNet** is a **lightweight, hierarchical deep learning system** for automatic ECG interpretation, designed and evaluated on the **PTB-XL** dataset under **strict, leakage-free conditions**.

The project demonstrates that **carefully designed, parameter-efficient neural architectures** can achieve **competitive diagnostic performance** compared to large CNNs (e.g., ResNet) while remaining **deployable in real-world clinical and edge environments**.

This repository represents an **end-to-end ML system** â€” from data preprocessing and training to evaluation, inference API, and interactive visualization.

---

## Key Contributions

- âœ… **Hierarchical multi-lead ECG modeling** (lead-wise â†’ global aggregation)
- âœ… **Sub-million parameter architecture** (~0.34M params)
- âœ… **Strict PTB-XL official splits** (no patient leakage)
- âœ… **Honest evaluation** (no test-set threshold tuning)
- âœ… **End-to-end deployment demo** (FastAPI + Streamlit)
- âœ… **Baseline comparison with ResNet**

---

## Problem Statement

ECG classification is typically addressed using:
- very large CNNs (10â€“60M parameters), or
- Transformer-based architectures with heavy compute requirements.

However, such models:
- are difficult to deploy on **edge / wearable devices**,
- often over-report performance due to **data leakage**,
- ignore **realistic performance ceilings** caused by label ambiguity.

> **Goal:**  
> Can a **lightweight, hierarchical neural network** achieve strong diagnostic performance on PTB-XL when evaluated correctly?

---

## Dataset

### PTB-XL (PhysioNet, 2020)

- ~21,800 ECG recordings  
- 12 leads  
- 10 seconds per ECG  
- Original sampling: 500 Hz (downsampled during preprocessing)
- Official **patient-level splits**:
  - Train: folds 1â€“8
  - Validation: fold 9
  - Test: fold 10

### Tasks

- **Multi-label classification (5 diagnostic superclasses)**
  - NORM, MI, STTC, CD, HYP
- **Binary classification**
  - MI vs Normal
  - Normal vs Abnormal

âš ï¸ **Important:**  
All experiments strictly follow official PTB-XL splits.  
There is **no patient leakage**, **no test-set tuning**, and **no post-hoc threshold optimization**.

---

## Architecture: HMT-ECGNet

### High-Level Design

12-Lead ECG (10s)
â”‚
â”œâ”€ Shared per-lead temporal encoder
â”‚
â”œâ”€ Lead-wise feature tokens
â”‚
â”œâ”€ Hierarchical cross-lead aggregation
â”‚
â”œâ”€ Global temporal pooling
â”‚
â””â”€ Classification head


### Design Principles

- **Per-lead temporal modeling** with shared weights
- **Hierarchical aggregation** instead of heavy attention
- **Explicit separation of temporal and spatial modeling**
- **Parameter efficiency first**, accuracy second

**Total parameters:** ~**338K**

---

## Training Protocol

- Optimizer: **AdamW**
- Learning rate schedule: **Cosine Annealing**
- Loss:
  - Multi-label: `BCEWithLogitsLoss` with class balancing
  - Binary: `BCEWithLogitsLoss`
- Regularization:
  - Signal preprocessing
  - Early stopping
- Reproducibility:
  - Fixed random seeds
  - Deterministic splits

---

## Results

### Multi-Label Classification (Test Set)

| Metric | HMT-ECGNet |
|------|-----------|
| AUROC (macro) | **â‰ˆ 0.92** |
| AUPRC (macro) | â‰ˆ 0.78 |
| F1 (macro) | â‰ˆ **0.73** |
| Parameters | **0.34M** |

---

### Binary Classification â€” MI vs Normal (Test Set)

| Metric | HMT-ECGNet |
|------|-----------|
| AUROC | **â‰ˆ 0.98** |
| Accuracy | â‰ˆ 0.92â€“0.93 |
| F1 | â‰ˆ **0.89** |

ğŸ“Œ **Observation:**  
Accuracy saturates due to ambiguous ECGs, while AUROC remains high â€” indicating strong class separability under realistic conditions.

---

## Baseline Comparison

| Model | Params | AUROC (Multi) | F1 (Multi) |
|------|--------|--------------|------------|
| **ResNet-1D** | ~8.7M | â‰ˆ 0.90 | â‰ˆ 0.70 |
| **HMT-ECGNet (ours)** | **0.34M** | **â‰ˆ 0.92** | **â‰ˆ 0.73** |

âœ” **HMT-ECGNet outperforms ResNet while using ~25Ã— fewer parameters**

---

## Error Analysis & Insights

- Ensemble models improve **stability**, not accuracy
- Remaining errors are **systematic**, not variance-driven
- Confirms a **performance ceiling** on PTB-XL due to:
  - label ambiguity,
  - inter-observer disagreement,
  - borderline ECG patterns

---

## Deployment Demo

This repository includes a **production-style demo**:

- **FastAPI** inference server
- **Streamlit** UI
  - Live ECG visualization
  - Real-time predictions
  - MI risk screening
- Uses **unseen PTB-XL test ECGs**

---

## Project Structure

hmt_ecgnet/
â”œâ”€â”€ artifacts/
â”‚ â”œâ”€â”€ mi_best.pth
â”‚ â”œâ”€â”€ multilabel_best.pth
â”‚ â”œâ”€â”€ multilabel_thresholds.json
â”‚ â””â”€â”€ resnet_baseline.pth
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ hmt_ecgnet.py
â”‚ â””â”€â”€ resnet1d.py
â”‚
â”œâ”€â”€ api.py
â”œâ”€â”€ app.py
â”œâ”€â”€ dataset.py
â”œâ”€â”€ train_multilabel.py
â”œâ”€â”€ train_binary.py
â”œâ”€â”€ eval_multilabel.py
â”œâ”€â”€ eval_binary.py
â”œâ”€â”€ threshold_search.py
â”œâ”€â”€ threshold_search_multilabel.py
â”œâ”€â”€ config.py
â””â”€â”€ README.md


---

## References

1. Wagner et al.  
   **PTB-XL: A Large Publicly Available Electrocardiography Dataset**  
   *PhysioNet, 2020*

2. Ribeiro et al.  
   **Automatic diagnosis of the 12-lead ECG using deep neural networks**  
   *Nature Communications, 2020*

3. Hannun et al.  
   **Cardiologist-Level Arrhythmia Detection with Deep Neural Networks**  
   *Nature Medicine, 2019*

4. Rajpurkar et al.  
   **Cardiologist-Level Arrhythmia Detection Using Deep Neural Networks**  
   *arXiv:1707.01836*

5. Tan & Le  
   **EfficientNet: Rethinking Model Scaling for CNNs**  
   *ICML, 2019*

---

## Disclaimer

This system is **for research and demonstration purposes only**  
and **not intended for clinical diagnosis or treatment**.

---

## Author Note

This project emphasizes:
- **engineering discipline**
- **honest evaluation**
- **deployment realism**
- and **model efficiency**

rather than leaderboard chasing.